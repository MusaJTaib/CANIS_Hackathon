{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760f1dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.utils import simple_preprocess\n",
    "import re\n",
    "\n",
    "# Read the input CSV file\n",
    "input_csv = \"Preprocessed_Dataset_Misinfo_TRUE.csv\"  # Replace with the actual file name\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# Create a new column to store the topics\n",
    "df[\"topics\"] = \"\"\n",
    "\n",
    "# Function to tokenize the text for topic modeling\n",
    "def tokenize(text):\n",
    "    return simple_preprocess(text)\n",
    "\n",
    "# Function to extract topic names from the topic string\n",
    "def extract_topic_names(topic_string):\n",
    "    return re.findall(r'\"(.*?)\"', topic_string)\n",
    "\n",
    "# Iterate through each row and process the text in column B\n",
    "for index, row in df.iterrows():\n",
    "    text = row[\"text\"]  # Assuming the column name is \"B\"\n",
    "\n",
    "    # Tokenize the text for topic modeling\n",
    "    tokenized_text = tokenize(str(text))\n",
    "\n",
    "    if tokenized_text:  # Check if the tokenized text is not empty\n",
    "        # Create the dictionary and the corpus for the LDA model\n",
    "        dictionary = corpora.Dictionary([tokenized_text])\n",
    "        corpus = [dictionary.doc2bow(tokenized_text)]\n",
    "\n",
    "        # Apply the LDA model\n",
    "        num_topics = 5  # Adjust the number of topics as needed\n",
    "        lda_model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=10)\n",
    "\n",
    "        # Save the topics in the dataframe\n",
    "        topics = lda_model.print_topics()\n",
    "        topic_names = [extract_topic_names(topic[1]) for topic in topics]\n",
    "\n",
    "        # Keep track of unique topics for each row\n",
    "        unique_topic_names = set()\n",
    "        for topic_name_list in topic_names:\n",
    "            for topic_name in topic_name_list:\n",
    "                if len(unique_topic_names) < 5:\n",
    "                    unique_topic_names.add(topic_name)\n",
    "                else:\n",
    "                    break\n",
    "            if len(unique_topic_names) == 5:\n",
    "                break\n",
    "\n",
    "        df.at[index, \"topics\"] = \", \".join(unique_topic_names)\n",
    "\n",
    "# Save the output as a new CSV file\n",
    "output_csv = \"Top5-topic_modeling_Preprocessed_Dataset_Misinfo_TRUE.csv\"\n",
    "df.to_csv(output_csv, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
